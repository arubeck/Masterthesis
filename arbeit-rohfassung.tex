\documentclass[12pt, a4paper]{scrartcl}

\usepackage[english]{babel}
\usepackage{ucs}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}

\usepackage[toc,page]{appendix}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{mathtools}

\usepackage{dirtytalk}
\usepackage{geometry}

\usepackage[protrusion=true,expansion=true]{microtype}
\usepackage{pdfpages}
\usepackage{tcolorbox}
\usepackage{xcolor}

\usepackage{tikz}
\usepackage{microtype}
\usepackage{natbib}

\usepackage{fancyvrb} 
\usepackage{bm}

\usepackage{tabularx,booktabs,ragged2e}

\usepackage[colorinlistoftodos]{todonotes}

\xdefinecolor{gray}{rgb}{0.4,0.4,0.4} 
\xdefinecolor{blue}{RGB}{58,95,205}
\xdefinecolor{dkgreen}{RGB}{7,90,1}
\xdefinecolor{mauve}{RGB}{178,42,110}
% R's royalblue3; #3A5FCD 

\usepackage{listings}
\lstset{ % 
	language=R,                % the language of the code 
	basicstyle=\footnotesize,           % the size of the fonts that are used for the code 
	numbers=left,                   % where to put the line-numbers 
	numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers 
	stepnumber=2,                   % the step between two line-numbers. If it's 1, each line 
	% will be numbered 
	numbersep=5pt,                  % how far the line-numbers are from the code 
	backgroundcolor=\color{white},      % choose the background color. You must add \usepackage{color} 
	showspaces=false,               % show spaces adding particular underscores 
	showstringspaces=false,         % underline spaces within strings 
	showtabs=false,                 % show tabs within strings adding particular underscores 
	frame=single,                   % adds a frame around the code 
	rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here)) 
	tabsize=2,                      % sets default tabsize to 2 spaces 
	captionpos=b,                   % sets the caption-position to bottom 
	breaklines=true,                % sets automatic line breaking 
	breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace 
	title=\lstname,                   % show the filename of files included with \lstinputlisting; 
	% also try caption instead of title 
	keywordstyle=\color{blue},          % keyword style 
	commentstyle=\color{dkgreen},       % comment style 
	stringstyle=\color{mauve}
}

\pagestyle{plain} %maybe headings, not sure yet
%\setlength{\parindent}{0pt}
%\setlength{\parskip}{\medskip} %XXX maybe change distance

\theoremstyle{definition}
\newtheorem{Algorithm}{Algorithm}[section]
\newtheorem{Definition}{Definition}[section]
\newtheorem{setting}{Setting}

\theoremstyle{plain}
\newtheorem{Theorem}{Theorem}[section]
\newtheorem{Lemma}{Lemma}[section]

\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}

\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\myrightarrow}[1]{\xrightarrow\makebox[2em]{c{$\scriptstyle #1$}}}
%\newcommand{\Pr}{\mathrm{Pr}}

\begin{document}
	
	\listoftodos
	\newpage

	\begin{center}
		\Huge Master Thesis\\
		\vspace{0.5cm}
		\LARGE University of Augsburg\\
		\vspace{0.3cm}
		Department of Mathematics\\
		\vspace{0.3cm}
		Chair for Computational Statistics\\ and Data Analysis
		\vspace{0.7cm}
		
		
	\end{center}
	\vspace{0.5cm}
	%\hrule\bigskip
	
	%\hrulefill
	\begin{figure}[h]
		\begin{center}
			\includegraphics[scale=1.35]
			{Uni_Aug_Siegel_32Grad_schwarz.png}
		\end{center}
	\end{figure}
	
	\begin{center}
		\vspace{0.4cm}
		{\LARGE{{Principles of Deep Learning for Survival Analysis}}}\\
		\vspace{2cm}
		\LARGE {Anna Sophie Rubeck}\\
		\vspace{0.9cm}
		\large{October 2021}
	\end{center}
	\pagenumbering{gobble}
	\newpage

	
	\thispagestyle{plain}
	\tableofcontents
	\newpage

	
	\pagenumbering{arabic}
	%\setcounter{page}{2}
	\section{Introduction} \label{introduction}
	
	Medicine, time to event analysis, missing data, want to apply ml algorithms as ...
	Machine learning has gained more and more interest in the last decades.
	The algorithms are of growing importance in many areas and can be extended to various types of data.
	
	problem: treatment of missing data;
	need specialized techniques as in contrast to standard regression or classification tasks the outcome can for example often not be fully observed
	
	In this thesis we describe XXX
	We start by pointing out the main ideas of survival analysis in Section~\ref{sec:sa}.
	The concept of censoring, the layout of survival data, as well as parametric and semiparametric approaches to survival analysis are described.
	Then we briefly describe deep learning focusing on feedforward networks.
	In Section~\ref{uncensored} we illustrate how deep learning can be used to analyze survival data in the case where no observation is censored.
	The main part of this thesis is Section~\ref{censored} where we consider censored data and how deep learning algorithms can be extended to account for this setting.
	For this we introduce censoring unbiased loss functions and how they can be used to estimate survival probabilities and restricted mean survival.
	Then we show that deep feedforward networks that use the censoring unbiased loss functions are equivalent to feedforward networks that use the $L_2$ loss with transformed data.
	The resulting algorithms are analyzed in a simulation study and tested using the Mayo clinic primary biliary cholangitis data. 
	\newpage
	
	\section{Principles of Survival Analysis}\label{sec:sa}
		
	In this section, following \citet*{sabook} and \citet*{mathsabook}, we briefly describe the main ideas of survival analysis, the concept of censoring, and parametric and semiparametric approaches to the problem of estimating survival times.
	
	Survival analysis is used in various fields such as medicine, insurance and finance to predict a certain risk.
	The main goal is to estimate and analyze the time until a specified event occurs.
	A medical application could be a study about the time to death after the outbreak of a disease.
	In this case the patient enters the study as soon as the disease is diagnosed.
	After a certain time the patient dies.
	As the event of interest is death we will refer to the time period between study entry and death as the \emph{true survival time}.
	In some cases we cannot observe the patient's true survival time due to censoring which will be explained in greater detail in Section \ref{censoring}.
	
	In this thesis we consider a single event of interest that can either occur or not.
	It is also possible to consider competing risks meaning that multiple different events that are taken into account.
	A detailed explanation of this case is for example given in \citet*[Chapter~8]{bookfailuretime}.
	We also assume that the event of interest can only take place once during the observed period.
	It is also possible to study recurrent events.
	In this setting events can happen to a subject multiple times.
	For further details refer to \citet*[Chapter~9]{bookfailuretime}.
	
	\subsection{Censoring} \label{censoring}
	
	This section relies on \citet*{sabook} and \citet*{mathsabook}.
	
	Survival data is often incomplete meaning that for some subjects the particular event is not observed within the study period.
	We refer to this data as censored.
	In this case we cannot observe the true survival time which is the time when the event occurs, but instead we observe the censoring time which is the time from which on the censored subject is no longer examined.
	The observed survival time is then either given by the true survival time (if we observe that the patient experiences the event) or the censoring time (if the patient is censored).
	
	Even though censored data is not observed until the event, it still contains valuable information about the time between the entry of the study and the event.
	Assuming data arising from a medical study, there are three possible reasons why censoring occurs:
	\begin{itemize}
		\item The study ends before a participant experiences the event.
		\item A participant is lost to follow-up during the study period. %XXX evtl follow-up erklären?
		\item A participant withdraws from the study or experiences a different event that makes further follow-up impossible.
	\end{itemize}

	The reasons mentioned above all lead to \emph{right censored} data.
	We call censored data right censored, if the true survival time is equal to or greater than the censoring time.
	
	There are two other types of censoring that may occur.
	If the true survival time is less than or equal to the observed censoring time, the data is \emph{left censored}.
	This could arise due to subjects that already experienced the event of interest before entering the study making the true event time unobservable.
	Consider analysis of the Corona disease where patients enter the study as soon as they experience symptoms.
	It is not possible to determine the exact time when the patient contracted the disease, thus leading to left censored data.
	A more general case is \emph{interval censoring}.
	It occurs if we only know that the true survival time lies within a specified time interval, but cannot observe it directly.
	The last case incorporates right censoring and left censoring as special cases.
	
	Even though censored data is not fully observed, we cannot treat them the same as uncensored data or even leave them out completely, as this would both lead to biased estimators.
	For example, if we treat censored subjects as if they experienced the event at their censoring time, we potentially ignore the time period between the drop out of the study and the event.
	This would lead to an artificially lowered survival curve.
		
	In this thesis we consider the data to be possibly right censored, but not left or interval censored.
	Further information about left and interval censoring can for example be found in \citet*{bookfailuretime}.
	
	\todo{passende Stelle für censoring assumptions finden}
	There are three main assumptions about censoring that are often required for further analysis, which are independent, random and non-informative censoring.
	To achieve random censoring, we assume that the failure rate for censored subjects is the same as the failure rate for the uncensored individuals that remain in the risk set.
	Independent censoring is the assumption that censoring occurs randomly within any subgroup of interest.
	The third assumption, namely that censoring is non-informative, means that given the explanatory variables, the distribution of survival times is conditionally independent of the distribution of censoring times.
	These assumptions are covered in greater detail in \citet*{bookfailuretime}.
	
	
	\subsection{Survival Analysis Data} \label{sabasics}
	
	This section mainly relies on \citet*{sabook}.
	
	We now describe how the survival data for each of the patients $i = 1, \dots, n$ can be represented.
	
	We denote by $T_i \geq 0$ the random variable for the true survival time of subject $i$ and by $C_i \geq 0$ the random variable for the censoring time of individual $i$.
	The variables $T_1,\dots,T_n$ and $C_1,\dots,C_n$ are each identically and independently distributed.
	As we consider right censored data, the observed time is given by $\tilde{T_i} = \min\{T_i,C_i\}$.
	We also observe $p$ specific characteristics for each subject that might play a role in the prediction of the survival time.
	These explanatory (or predictor) variables are known for each individual and given by the vector $X_i = (X_{i1}, \dots , X_{ip}) \in \delta \subset \mathbb{R}^p$, where $\delta$ denotes the bounded space consisting of all possible values that the explanatory variables can take.
	The event indicator $\Delta_i = I(T_i \leq C_i)$ specifies whether subject $i$ has experienced the event of interest ($\Delta_i=1$) or the data is censored ($\Delta_i=0$).
	
	Then the basic data layout has the form $(\tilde{T}_i, \Delta_i, X_i)$, $i = 1, \dots , n$, where $n$ is the number of patients included in the study.
	
	As it is common in the literature we will not further distinguish notationally between a random variable and its realization.
	
	%\todo[inline]{outcome is possibly transformed: h(T) instead of T}
	
	Two important functions are frequently used for analysis and prediction of survival times:~the survival function and the hazard function.
	The survival function $S(t) = P(T > t)$ specifies the distribution of the survival time given by $F(t) = 1 - S(t)$.
	It can for example be used to analyze and compare the time to event of two different groups.
	The survival function has three important properties: $S(\cdot)$ is a non-increasing function, $S(0)=1$ and $\lim_{t \to \infty} S(t)=0$.
	These properties follow directly from the relation $F(t)=1-S(t)$ and that $F$ is a proper distribution function.
	
	The hazard function $h(\cdot)$, also called conditional failure rate, is given by
	\begin{equation*}
		h(t) = \lim_{\Delta t \to 0}\frac{P(t \leq T < t + \Delta t \vert T \geq t)}{\Delta t}.
	\end{equation*} 
	
	It is a measure of instantaneous potential to experience the event and can be used to identify a specific model form.
	
	The hazard function has two important properties: it is a non-negative function, i.e.~$h(t) \geq 0$ $ \forall t$, and it has no upper bound.
	In contrast to the survival function $S(\cdot)$, the hazard function does not necessarily have any monotonicity properties.

	There exists a clearly defined relationship between the survival function $S(t)$ and the hazard function $h(t)$:
	\begin{equation*}
	\begin{split}
		S(t) &={} \exp \left( - \int_{0}^{t}h(u)du\right) \\
		h(t) & ={} - \left[ \frac{dS(t)/dt}{S(t)}\right].
	\end{split}
	\end{equation*}
	As a consequence, specifying one of the two functions directly gives the other one.
	
	%XXX - KM curves, log rank test
	
	%\todo[inline]{add: counting process allows definition of (point) estimators, mathsabook p. 140 and Chapter 3.6}
	
	\subsection{(Semi-)Parametric Approaches to Estimation of Survival Time} \label{cox}

	This section relies on \citet*{sabook}.
	
	An approach to the estimation of survival time are \emph{parametric survival models}.
	Here, we assume a specific family of distributions for the survival time and then use the given data to estimate the parameters of the distribution.
	These parameters can for example be estimated using linear, logistic or Poisson regression.
	Common choices for the family of distributions when analyzing survival times are the Weibull, exponential or lognormal distribution.
	The parametric approach is discussed in further detail in \citet*{sabook}.
	
	Three of the main advantages of the parametric survival model are its simplicity,  that it is consistent with the theoretical survival function $S(\cdot)$ and that it specifies the whole survival function.
	
	A big disadvantage is that the quality of the estimation using parametric models strongly depends on a suitable choice of the family of distributions.
	As a consequence, a detailed analysis of the data and a precise understanding of the families of distributions are required.
	The Cox proportional hazard model tries to overcome these limitations by relaxing the parametric approach and is described in the following.
	
	The \emph{Cox proportional hazards model} (Cox PH model) is a popular approach to analyzing survival data.
	The model is built upon the following assumption about the form of the hazard function:
	\begin{equation*}
	h(t,x) = h_0(t) \exp \left(\sum_{i=1}^p \beta_i x_i\right),
	\end{equation*}
	where $x=(x_1,\dots,x_p)$ are the explanatory variables and $\beta = (\beta_1,\dots, \beta_p)$ is a vector of weights.
	This includes the central assumption of the Cox PH model, which is the proportional hazards (PH) assumption.
	It states that there exists a function $h_0$, the \emph{baseline hazard}, that does not involve the predictor variables and is thus independent of the explanatory variables.

	Typically, maximum likelihood is used to estimate the weights $\beta_i$, $i=1,\dots ,p$.
	As the baseline hazard $h_0$ is not specified, the Cox PH model is a semiparametric model.
	
	In contrast to parametric models, the Cox PH model does not require an assumption about the distribution of the outcome.
	Another important advantage is its robustness, meaning that it closely approximates the correct parametric model of the survival function.
	
	If we are sure which family of distributions models the survival times adequately, parametric models give the best estimate.
	But if we are in doubt that the model is a good fit, the Cox PH model gives reliable results.
	
	As it is necessary for the performance of the Cox PH model that the PH assumption holds, there are several tests that can be performed, e.g. graphical techniques or goodness-of-fit-tests.
	Further details can for example be found in \citet*[Chapter~3]{sabook}.
	
	If the PH assumption is not fulfilled, we can for example use a stratified Cox procedure instead, a modified version of the Cox PH model.
	The general idea is to categorize the data and divide it into subgroups in a way that within each subgroup the PH assumption is met.
	Then for each subgroup the Cox PH model can be applied to obtain partial likelihood functions, which can then be combined to an overall likelihood.
	This approach is explained in greater detail in \citet*[Chapter~5]{sabook}.
	
	There exist various other modifications of the Cox PH model.
	
	In many cases it may be too simplistic to assume that the effect of the explanatory variables is linear, as it is the case for the Cox PH model.
	Thus, we need a richer family of survival models to properly fit survival data with nonlinear risk functions.
	
	One possible approach to compensate for this disadvantage is to use deep learning procedures.
	In this thesis, we take a closer look at this approach.
	But first, we introduce the main ideas of deep learning and explain the idea of feedforward networks.
	\newpage
	
	\section{Principles of Deep Learning}\label{basicsdl}
	This section relies on \citet*{deeplbook}.
	
	Machine learning describes a broad class of algorithms having the goal to learn or extract information from a given sample without the need of explicit programming.
	To achieve this goal machine learning algorithms require a task and a performance measure.
	Such a task could be to recognize whether a cat or a dog is on a picture, given examples of already classified pictures.
	The algorithm then builds a prediction model based on a given training set.
	In the example above the training set consists of pictures of cats and dogs and corresponding labels specifying what is visible on the respective picture.
	The performance measure then describes how well this task was achieved by calculating some sort of distance between the predicted label and the real label that is given in the training set.
	It is a key requirement to specify a suitable performance measure when applying machine learning algorithms.
	
	%Machine learning algorithms are often classified according to what kind of experience they are allowed to have during the learning process.

	The central challenge for a machine learning algorithm is that it must perform well on new and previously unseen inputs meaning that the error measure on the test set should be as small as possible and at the same time the error measure on the training set should also be reduced.
	This means that there are two factors that determine how well a machine learning algorithm will perform:
	make the training error small and make the gap between the training and the test error small.
	
	If the first task is not fullfilled, underfitting occurs. This means that the error value on the training set is not sufficiently low for our model.
	If the second task is not fullfilled, overfitting occurs. In this case, the gap between training and test error is too large.
	
	A common approach to reduce the possibility of overfitting is regularization.
	In principle, regularization is any modification of a learning algorithm that aims to reduce its generalization error.
	In practice this is often achieved by adding a penalty to the cost function.
	
	Deep learning models are machine learning models that are based on artificial neural networks.
	A common class of deep learning models are deep feedforward networks. Analogous to other estimators they aim to approximate some function~$f^*$.
	More precisely, given the data~$x$ and the desired output~$y$, the goal is to find $f^*$, such that $f^*(x)=y$.
	This is achieved by defining a mapping $y = f(x; \beta)$ and learning the parameters $\beta$ that result in the best function approximation.
	In this setting loss functions are used as a performance measure.
	Possible choices include the $L_2$ loss or the Brier loss which are both further described in Section \ref{censored}.
	
	The term 'network' suggests that the mapping $f$ is a composition of many different functions.
	A directed acyclic graph is used to describe how these functions are composed together in the model.
	For example, the network could consist of a chain of $K$ functions $ f = f^{(K)}\circ \dots \circ f^{(1)}$.
	In this case each function~$f^{(k)}$, $k=1,\dots,K$ forms a layer and the number of composed functions $K$ gives the depth of the model.
	The dimension of the output of each layer $f^{(k)}$ is denoted by $n_k$ and determines the width of the layer.
	Typically these functions are vector-valued and instead of thinking of the layer as a vector-to-vector function, we can interpret it as many \emph{units} that each represent a vector-to-scalar function.
	Considering $f^{(1)}(x,y)= (x^2+y,2y)$ we can represent the function by two units $f^{(1)}_1 (x,y) = x^2+y$ and $f^{(1)}_2(x,y) = 2y$.
	
	The final layer is called the output layer.
	We want to achieve that this layer produces a value that is close to the desired output $y$, i.e. for each data $x$ and corresponding label $y$: $y \approx f^*(x)$.
	
	The remaining layers are called hidden layers because their results and their inner workings do not constitute the observed output of the network.
	We are only interested in the prediction, the output of the final layer.
	Before creating a deep feedforward network it is necessary to determine the structure of the associated directed acyclic graph.
	This is achieved by setting the number of units and specifying how these units are connected.
	
	In the model each of the units $f^{(k)}_i$, $k=1,\dots,K$, $i = 1,\dots,n_{k}$ is associated with a vector of weights~$a^{(k)}_i \in \mathbb{R}^{n_{k-1}}$, a bias term~$b^{(k)}_i\in \mathbb{R}$ and an activation function~$\phi: \mathbb{R} \to \mathbb{R}$.
	The output of each unit $f^{(k)}_i$, $k=1,\dots,K$ is then computed as
	\begin{equation*}
	f_i^{(k)}(y) = \phi \left(\left(a^{(k)}_i\right)^Ty + b^{(k)}_i\right),
	\end{equation*}
	where $y$ is the output of layer $f^{(k-1)}$.
	These units are then combined to form the output of the whole layer which is given by $f^{(k)} = \left(f^{(k)}_1,\dots, f^{(k)}_{n_k}\right)^T$.
	The output of the first layer $f^{(1)}$ is computed using the data $x$ as input and $n_0$ is defined as the dimension of $x$.
	Popular choices for the activation function are the ReLU activation function given by $\phi(x) = \max(0,x)$ or the sigmoid activation function given by $\phi(x) = (1+e^{-x})^{-1}$.
	The weights and the biases make up the learning parameter $\beta$.
	
	The above described procedure can be used to iteratively compute the output of the final layer.
	
	A central question in dealing with feedforward networks is how to determine appropriate weights and biases.
	There are several techniques for this training procedure for instance stochastic variants of gradient descent.
	
	The networks described above are called feedforward networks because information only travels in one direction from input to output, i.e. there are no feedback connections between the layers.
	This is the reason why we require the associated graph to be acyclic.
	
	When building deep feedforward networks, overfitting can occur.
	A common approach to counteract this phenomenon is a regularization method called dropout.
	According to \citet*{dropout} the idea is to randomly drop units from the neural network during each step of the learning algorithm.
	For this method, a dropout rate $p$ must be chosen which specifies that a unit is included in the current iteration with probability $1-p$.
	As a consequence, each of the hidden units must be able to perform well regardless of the other units included in the model and the co-dependence is minimized.
	Further details about dropout regularization can be found in \citet*{dropout}.
	
	In the following section we describe how survival data can be analyzed using feedforward networks
	
	\newpage
	
	\section{Deep Learning for Fully Observed Data} \label{uncensored}
	This section follows the ideas of \citet*{basearticle} and insights described in \citet*{deeplbook}.
	
	As described in Section \ref{sabasics}, we assume that the dataset consists for each subject $i = 1,\dots,n$ of a positive continuous failure time $T_i \in \mathbb{R}^+$ and a vector of explanatory variables $X_i = (X_{i1}, \dots , X_{ip}) \in \delta \subset \mathbb{R}^p$.
	In the context of a medical study these explanatory variables could for example be age, in which treatment group the patient was or the oxygen concentration in blood at the beginning of the study.
	The set $\delta$ describes the bounded space consisting of all values that the explanatory variables can take in the specific context.
	In the example described above, a possible choice for $\delta$ could be $\delta = [0, 120] \times \{0,1,2\} \times [50, 200]$.
	We assume that the outcome $T_i$ is possibly transformed via a monotone function $h: \mathbb{R}^+ \rightarrow \mathbb{R}$.
	%XXX kurze Erklärung wieso das h sinnvoll ist bzw gebraucht wird
	Possible choices for this transformation are for instance the identity function $h(t)=t$ or the logarithmic transformation $h(t)= \ln (t)$.
	
	In this section we assume that the data is not censored.
	As a consequence, the event indicator is not required and the data set reduces to the fully observed data given by
	\begin{equation*}
	\mathcal{F} =\{ \left( h(T_i), X_i\right); i = 1, \dots, n\}.
	\end{equation*}
	
	We now describe the structure of a deep learning algorithm based on feedforward networks for fully observed data, as presented in \citet*{basearticle}.
	
	\begin{Algorithm}\label{alg:nocensor}
		~
	\begin{enumerate}
		\item Setup the structure of the neural network.
		\item Estimate the learning parameter.
		\item Use cross-validation to select the penalization parameter $\eta$ from a predetermined sequence $\eta_1,\dots,\eta_M$.
		\item Create the final prediction model.
	\end{enumerate}
	\end{Algorithm}

	We now further analyze these steps.

	First we define the layout of the neural network that we want to use for our prediction.
	For this, we need to set the number of layers $K$ and define the functions $f_{\beta_k}^{(k)}$ for each layer $k = 1, \dots, K$.
	The output of the hidden layer architecture is then given by $f_{\beta}(X) = f_{\beta_K}^{(K)} \circ f_{\beta_{K-1}}^{(K-1)} \circ \dots \circ f_{\beta_1}^{(1)}(X)$, where $\beta = (\beta_1^T, \dots, \beta_K^T)^T$ is a vector of unknown weights and biases which will be estimated next.
	
	In the second step, the estimation of the learning parameter, we need a prespecified loss function $L(h(T), f(X))$ that describes the difference between the prediction of our model $f(X)$ and the desired outcome $h(T)$.
	As we described in Section \ref{basicsdl} the learning parameter $\beta$ consists of weights and biases.
	We also use a penalization parameter~$\eta$ to try to keep the learning parameter as small as possible.
	Large weights can be a sign of a complex network and thus overfitting of the training data.
	To counteract this effect, we penalize such large weights.
	We estimate the learning parameter $\beta$ by minimizing the empirical penalized loss function $\hat{L}$ which is defined as:
	
	\begin{equation}\label{eq:eplf}
	\hat{L}(\beta) = \frac{1}{n} \sum_{i=1}^n L( h(T_i), f_{\beta}(X_i)) + \eta \Vert \beta \Vert ^2,
	\end{equation}
	
	where $\Vert \beta \Vert ^2$ is the $L_2$ norm of $\beta$, given by $\Vert \beta \Vert ^2 = \sum_{i=1}^q \vert \beta _i \vert ^2.$
	
	The third step ensures that we make a suitable choice for the penalization parameter~$\eta$.
	To perform cross-validation, we first split the given dataset randomly into~$D$ disjoint sets $K_1,\dots, K_D$ and choose a sequence of $M$ possible penalization parameters.
	Suitable choices for $\eta$ strongly depend on the model architecture.
	A detailed analysis for neural networks with one hidden layer is given in \citet*{regpar}. 
	Then, for a fixed subset $K_{\ell}$, $\ell \in \{1,\dots,D\}$ and penalization parameter $\eta_m$, $m \in \{1,\dots,M\}$, we set $\hat{\beta}_{\eta_{m}}^{(\ell)}$ as the learning parameter estimated in equation~(\ref{eq:eplf}) using the penalization parameter~$\eta_m$ and the data~$\mathcal{F} \setminus K_{\ell}$.
	Let $a_{i,\ell}$ be the indicator whether observation $i$ is included in the dataset~$K_\ell$ ($a_{i,\ell} = 1$) or not ($a_{i,\ell}=0$).
	The cross-validation error corresponding to the penalization parameter~$\eta_m$ is then defined as
	
	\begin{equation*}
	 \alpha(m) = \sum_{l=1}^D \sum_{i=1}^n a_{i,l} L(h(T_i), f_{\hat{\beta}_{\eta_m}^{(l)}}(X_i)).
 	\end{equation*}
 	Then we choose the penalization parameter that minimizes the cross-validation error for our model, i.e. let $\eta = \eta_{m^*}$, where $m^* = \argmin_{m \in \{1,\dots,M\}} \alpha(m)$.
 	
 	In step four we use the optimal penalization parameter $\eta_{m^*}$ to estimate the learning parameter $\hat{\beta}_{\eta_{m^*}}^{(l)}$ and then build the final prediction model $f_{\hat{\beta}_{\eta_{m^*}}^{(l)}}$.
 	
 	The learning parameter $\beta(X)$ that is estimated using the explanatory variables $X$ minimizes the expected loss used in the algorithm.
 	Thus, the parameter that we want to estimate determines the choice of loss function.
 	If we use for example the $L_2$ loss, the population parameter estimated by the full data deep learning algorithm is the conditional mean $E[h(T) \vert X]$.
 	If we instead want to estimate survival probabilities $P(T\geq t \vert X )$ for a fixed time point $t$, we can use the Brier loss which is given by $E[(I(T\geq t)-\beta(X))^2]$.
 	
 	In the next section we describe how Algorithm \ref{alg:nocensor} can be extended to possibly censored data.
 	
	\newpage
	\section{Deep Learning for Censored Data} \label{censored}
	
	This section relies on \citet*{basearticle} as well as \citet*{deeplbook}.
	
	In this section we will now allow for the dataset to contain censored data meaning that in some cases we cannot observe the true event time of an individual.
	
	The observed dataset consists of $n$ independent and identically distributed observations and is given by
	$$\mathcal{O} = \{(\tilde{T_i} = \min \{T_i, C_i\}, \Delta_i = I(T_i \leq C_i), X_i); i = 1,\dots,n\},$$
	 where $\tilde{T_i}$ denotes the observed time, which is either the event time $T_i$ or the censoring time $C_i$, and $\Delta_i$ indicates whether subject $i$ experienced the event of interest or was censored.
	 Again, the explanatory variables are given by $X_i$.
	 
	 We define the true conditional survival functions for the event time $T$ and the censoring time $C$ as $S_0(u \vert X)=P(T>u \vert X)$ and $G_0(u \vert X)=P(C>u \vert X)$ respectively.
	 \todo{evtl zugehörige Verteilungsfunktion hier mit rein nehmen}
	 In contrast to Section \ref{sabasics} the survival function now depends on the explanatory variables $X$.
	 We assume that the censoring time $C$ is continuous and that the corresponding censoring mechanism is non-informative, i.e. that $C$ is independent of $T\vert X$.
	 
	 For further computations we also assume that $G_0(T \vert X)\geq \varepsilon > 0$ for some $\varepsilon >0$, to ensure positivity of the conditional censoring function.
	 We refer to this as the positivity assumption.
	
	The main difficulty in extending Algorithm \ref{alg:nocensor} to allow for censored data is to define a suitable loss function that can be computed in the presence of censoring and at the same time reduces to the full data loss $L(h(T), f(X))$ if the data is not censored.
	To close the gap between what is done in the presence and absence of censoring, we will now define \textit{censoring unbiased transformations}.
	
	\subsection{Censoring Unbiased Transformations}\label{sec:drtrafo}
	This section is based on \citet*{culs} and \citet*{drcut}.
	
	For prediction with right censored data, it is a popular approach to replace the possibly censored observations $\tilde T$ with surrogate values.
	This can be achieved by using an appropriate mapping $$Y^*(\cdot): \mathbb{R}^+ \to \mathbb{R}.$$
	The transformed values are then inserted in standard smoothing algorithms.
	
	In our case the key requirement is that the mapping $Y^*(\cdot)$ is a censoring unbiased transformation, which is defined as follows.
	
	\begin{Definition}
	Let $\tilde T$ be a scalar function of the full data $\mathcal{F}$ and $Y^*(\mathcal{O})$ a scalar function of the observed data $\mathcal{O}$.
	Then $Y^*(\mathcal{O})$ is a \textit{censoring unbiased transformation (CUT)} for $\tilde T$ if for every point $X$ in $\delta$:
	\begin{equation*}
	E[Y^*(\mathcal{O}) \vert X] = E[\tilde T \vert X].
	\end{equation*}
	\end{Definition}

	In other words, a censoring unbiased transformation maps the observed time $\tilde T$ in a way that it keeps its conditional mean structure.
	
	We will now take a closer look at three specific CUTs: the Buckley--James transformation, the inverse probability of censoring weighted mapping and a doubly robust censoring unbiased transformation.
	
	The Buckley--James transformation is given by
	
	\begin{equation}\label{eq:bjtrafo}
		Y_{BJ}^* (\mathcal{O}; S) = \Delta \tilde{T} + (1-\Delta)m(C,X;S),
	\end{equation}
	where
	\begin{equation}\label{eq:condmean}
		m(t,X;S) = E_S[\tilde{T} \vert \tilde T > t, X] = -\frac{1}{S(t\vert X)} \int_t^{\infty} u dS(u\vert X)
	\end{equation}%XXX
	and $S(\cdot\vert X)$ denotes the conditional survival function.
	
	%XXX explain \tilde T, C
	
	This transformation is rather intuitive.
	For an uncensored subject, i.e. $\Delta = 1$, the response remains unchanged.
	If the response is censored, i.e. $\Delta = 0$, it is mapped to its conditional expectation. %%%besser formulieren, klingt bissi holprig
	
	\begin{Theorem}\label{thm:bj}
		Under the mild regularity conditions given in Appendix~\ref{regcond} it holds that $Y_{BJ}^*(\cdot; S_0)$ is a CUT.
	\end{Theorem}
	
	The proof is given in Appendix \ref{proof:bjcut} and follows the ideas in \citet*{drcut} with $G(t\vert X)=1$ for all $t$.
	
	The Buckley--James Transformation has an important property.
	Among all CUTs~$Y^*(\cdot)$ the mapping~$Y_{BJ}^* (\cdot)$ results in the best predictor of the original response, i.e.
	\begin{equation*}
	Y_{BJ}^* (\mathcal{O})= \argmin_{\text{$Y^*(\cdot)$~is~a~CUT}} E[ \vert Y^*(\mathcal{O}) - \tilde T \vert ^2].
	\end{equation*}
	
	On the other hand, it requires the correct specification of the survival function~$S(\cdot\vert X)$.

	In contrast to the Buckley--James transformation, which depends on the survival function $S(\cdot\vert X)$, it is also possible to build mappings that instead depend only on the censoring mechanism.
	One example for this is the inverse probability of censoring weighted (IPCW) mapping.
	Here, the basic idea is to weight the contribution of each uncensored observation by the inverse probability of being censored.
	This way both distributions, the censoring and the survival distributions, are taken into account.
	The IPCW mapping is defined as follows:
	\begin{equation*}
	Y_{IPCW}^*(\mathcal{O}; G) = \frac{\Delta \tilde T}{G(\tilde T \vert X)}.
	\end{equation*}

	For the IPCW transformation we need to estimate the conditional censoring function given the explanatory variables $G(\cdot\vert X)$.
	If this function is modeled correctly, meaning that $G(\cdot\vert X)=G_0(\cdot\vert X)$, the IPCW transformation $Y_{IPCW}^*(\cdot; G_0)$ is a CUT.
	This claim is stated in the following theorem.
	\begin{Theorem}
		Under the regularity conditions given in Appendix \ref{regcond} the IPCW transformation $Y_{IPCW}^*(\cdot; G_0)$ is a CUT.
	\end{Theorem}
	\begin{proof}
		The desired property can be proven by using the tower rule
		\begin{equation*}
		\begin{split}
		E\left[Y_{IPCW}^*(\mathcal{O}; G_0)\vert X\right] &={} E\left[\frac{\Delta \tilde T}{G_0(\tilde T\vert X)}\vert X\right] = E\left[E\left[\frac{\Delta \tilde T}{G_0(\tilde T\vert X)}\vert X, \tilde T\right]\vert X\right]\\
		&={} E\left[\frac{\tilde T}{G_0(\tilde T \vert X)}P(\Delta = 1 \vert X, \tilde T)\right]
		\end{split}
		\end{equation*}
		Now we can use that $P(\Delta = 1\vert X, \tilde T) = 1-P(\Delta = 0\vert X, \tilde T)$ to obtain
		\begin{equation*}
		E\left[Y_{IPCW}^*(\mathcal{O}; G_0)\vert X\right] = E\left[\frac{\tilde T}{G_0(\tilde T \vert X)}G_0(\tilde T \vert X)\vert X\right] = E[\tilde T \vert X].
		\end{equation*}
		
	\end{proof}
		
	The IPCW transformed data is a weighted version of the observed time with weights
	\begin{equation}\label{eq:ipcw}
	\omega_{IPCW}(\mathcal{O}; G) = \frac{\Delta}{G(\tilde T \vert X)}.
	\end{equation}

	The Buckley--James estimator, as well as the IPCW mapping, depend on the nuisance parameters $S(\cdot\vert X)$ and $G(\cdot\vert X)$ respectively.
	As a consequence, poor estimators of these two conditional functions can significantly degrade the performance of regression applied to the transformed data.
	
	A third mapping is the doubly robust mapping.
	In this context \say{doubly robust} implies that the mapping requires a good approximation of either  $S(\cdot\vert X)$ or $G(\cdot\vert X)$, but not necessarily both.
	It is defined as follows:
	\begin{equation}\label{eq:drcut}
	Y_{DR}^* (\mathcal{O}; G, S) = \frac{\Delta \tilde T}{G(\tilde T\vert X)} + \frac{(1-\Delta)m(C,X;S)}{G(C \vert X)} - \int_{0}^{\tilde T} \frac{m(c,X;S)}{G(c \vert X)} d\Lambda_G(c \vert X),
	\end{equation}
	with $m(c,X;S)$ as defined in Equation (\ref{eq:condmean}) and the cumulative hazard function $\Lambda_G(t\vert X)=-\int_{0}^{t}1/G(u\vert X)dG(u\vert X)$.
	
	The first term in Equation (\ref{eq:drcut}) is as in the IPCW transformation.
	Similar to the Buckley--James transformation, a term that considers the censored data is added.
	The last part can be seen as an augmentation term.
	In total, the doubly robust transformation can be interpreted as an augmented inverse probability weighted mapping.
	For further details about the augmentation refer to \citet*{bookfailuretime}.
		
	We can show the double robustness property using Theorem 3.1 in \citet*{drcut} which is reproduced below.
	
	\begin{Theorem}\label{thm:dr}
		Assume that the regularity conditions given in Appendix \ref{regcond} are met.
		Then, if either $S_0(\cdot\vert X)$ or $G_0(\cdot\vert X)$ are specified correctly, i.e. $\tilde{S}(\cdot\vert X)=S_0(\cdot\vert X)$ or $\tilde{G}(\cdot\vert X)=G_0(\cdot\vert X)$, it holds that
		\begin{equation*}
		E[Y_{d}^*(\mathcal{O};\tilde{G}, \tilde{S})\vert X] = E[\tilde T \vert X],
		\end{equation*}
		with 
		\begin{equation}\label{eq:drcut2}
		Y_d^*(\mathcal{O}; G,S) = \frac{\Delta \tilde T}{G(\tilde T\vert X)}+\frac{(1-\Delta)m(C,X;S)}{G(C \vert X)}-\int_{-\infty}^{Y}\frac{m(c,X;S)}{G^2(c\vert X)}dF(c\vert X)
		\end{equation}
	\end{Theorem}
	In the following lemma we show that the transformations $Y_d^*$ and $Y_{DR}^*$ are equivalent and thus Theorem 5.1 can be applied to show that $Y_{DR}^*(\cdot; G_0, \tilde{S})$, $Y_{DR}^*(\cdot; \tilde{G}, S_0)$ and $Y_{DR}^*(\cdot; G_0, S_0)$ are each CUTs.
	
	\begin{Lemma}
		Assuming the regularity conditions given in Appendix \ref{regcond} it holds that $Y_{DR}^*(\mathcal{O}; G_0, \tilde{S})$, $Y_{DR}^*(\mathcal{O}; \tilde{G}, S_0)$ and $Y_{DR}^*(\mathcal{O}; G_0, S_0)$ are each CUTs.
	\end{Lemma}
	\begin{proof}
		We verify the lemma by proving that $Y_d^*$ and $Y_{DR}^*$ both perform the same transformation and as a consequence Theorem \ref{thm:dr} can be applied to $Y_{DR}^*$.
		The first two terms of the transformation $Y_d^*$ are equal to those in the transformation $Y_{DR}^*$.
		Thus it is sufficient to show that
		\begin{equation*}
		\int_{-\infty}^{Y}\frac{m(c,X;S)}{G^2(c\vert X)}dF(c\vert X) = \int_{0}^{Y} \frac{m(c,X;S)}{G(c \vert X)} d\Lambda_G(c \vert X).
		\end{equation*}
		As we only consider positive event times the censoring distribution is only defined for nonnegative values.
		Thus the lower bound of the left hand integral can be set to 0.
		\begin{equation*}
		\begin{split}
		\int_{-\infty}^{Y}\frac{m(c,X;S)}{G^2(c\vert X)}dF(c\vert X) &={} \int_{0}^{Y}\frac{m(c,X;S)}{G^2(c\vert X)}dF(c\vert X)\\
		&={} \int_{0}^{Y}\frac{m(c,X;S)}{G^2(c\vert X)}d(-G(c\vert X))
		\end{split}
		\end{equation*}
		For the second step we used the relation $F(\cdot\vert X)= 1-G(\cdot\vert X)$ and that a constant term in the integrator vanishes.
		Next, we use the definition of the cumulative hazard function and that according to the regularity conditions $G(\cdot \vert X)$ has a density function $g(\cdot \vert X)$
		\begin{equation*}
			\Lambda_G(c \vert X) = - \int_{0}^{c}\frac{1}{G(u\vert X)}dG(u\vert X) = - \int_{0}^{c}\frac{g(u\vert X)}{G(u\vert X)}du.
		\end{equation*}
		The fundamental theorem of calculus then gives
		\begin{equation*}
		\frac{d\Lambda_G(c \vert X)}{dc} = -\frac{g(c\vert X)}{G(c\vert X)}.
		\end{equation*}
		Using this identity and the density of $G$ yields
		\begin{equation*}
		\begin{split}
		\int_{-\infty}^{Y}\frac{m(c,X;S)}{G^2(c\vert X)}dF(c\vert X) &={} \int_{0}^{Y}\frac{m(c,X;S)}{G^2(c\vert X)}d(-G(c\vert X))\\
		& ={} \int_{0}^{Y}\frac{m(c,X;S)}{G(c\vert X)}\frac{(-g(c\vert X))}{G(c\vert X)}dc\\
		&={} \int_{0}^{Y}\frac{m(c,X;S)}{G(c\vert X)}\frac{d\Lambda_G(c \vert X)}{dc}dc\\
		&={} \int_{0}^{Y}\frac{m(c,X;S)}{G(c\vert X)}d\Lambda_G(c \vert X).
		\end{split}
		\end{equation*}
		As a consequence Theorem \ref{thm:dr} can also be applied for $Y_{DR}^*$ and we obtain that the doubly robust transformation is a CUT if the survival function $S(\cdot\vert X)$ or the censoring function $G(\cdot\vert X)$ are specified correctly.
	\end{proof}

	\subsection{Censoring Unbiased Loss Functions}\label{sec:cudls}
	This section follows the ideas presented in \citet*{culs} and \citet*{basearticle}.
	
	The theory of censoring unbiased transformations can be directly applied to loss functions and results in a class of censoring unbiased loss functions. 
	These loss functions can be computed in the presence and absence of censoring, and reduce to the full data loss if the survival time is not censored.
	
	In this thesis we focus on estimation of the expected loss~$\mathcal{R} (\beta) = E[L(h(T),\beta(X))]$, where $\beta(X)$ is the learning parameter estimated using the explanatory variables $X$.
	For this we consider two censoring unbiased estimators that both reduce to the full data loss in the absence of censoring: the doubly robust loss function and the Buckley--James estimator.
	We will not consider the IPCW transformed loss as censored observations are not taken into account apart from potentially through computation of the censoring function $\hat{G}$.
	According to \citet*{basearticle-arxiv} this leads to an inefficient estimator for the full data loss.
	
	The Buckley--James estimator for $\mathcal{R}(\beta)$ is given by
	\begin{equation}\label{eq:bj}
	L_{BJ}(\mathcal{O}, \beta; S_0) = \frac{1}{n} \sum_{i=1}^n \left[ \Delta_i L(h(T_i), \beta(X_i))+(1-\Delta_i)m_L(C_i, X_i, \beta; S_0)\right].
	\end{equation}
	This estimated loss function is the average of the Buckley--James transformed full data loss.
	
	Again, the structure of this estimator is rather intuitive.
	For uncensored observations we add the full data loss $L(h(T_i), \beta(X_i))$ and for censored observations we use the expectation of the full data loss $m_L(C_i, X_i, \beta; S_0)$ given by equation (\ref{eq:exploss}).
	
	In order to well-estimate $\mathcal{R}(\beta)$, this loss function requires to find a suitable estimator for the conditional survival function $S_0(\cdot\vert X)$.
	
	The doubly robust loss function is defined as
	\begin{equation}\label{eq:dr}
	\begin{split}
		L_{DR}(\mathcal{O}, \beta; G_0, S_0) ={} & \frac{1}{n} \sum_{i=1}^n \frac{\Delta_i L(h(T_i),\beta(X_i))}{G_0(\tilde{T}_i\vert X_i)}\\
		~ & + \frac{1}{n} \sum_{i=1}^n \left(\frac{(1-\Delta_i)m_L(\tilde{T_i}, X_i, \beta; S_0)}{G_0(\tilde{T_i}\vert X_i)} \right.\\
		& - \left. \int _0^{\tilde{T_i}} \frac{m_L(u, X_i, \beta; S_0)}{G_0(u \vert X_i)} d \Lambda_{G_0}(u \vert X_i) \right),
	\end{split}
	\end{equation}
	where for a survival curve $S$
	\begin{equation}\label{eq:exploss}
	\begin{split}
		m_L(u,x,\beta; S) &={} E_S[L(h(T), \beta(X)) \vert T \geq u, X = x]\\
		&={} - \int_u^{\infty} \frac{L(h(t), \beta(x))}{S(u \vert w)} dS(t\vert w)
	\end{split}
	\end{equation}
	and $\Lambda_G(u\vert X) = - \int_0^u  1/ G(t\vert X)dG(t \vert X)$ is the cumulative hazard function.
	
	Again, we obtain this loss function by computing the average of the full data loss that is now transformed via equation (\ref{eq:drcut}).
	
	Theorem \ref{thm:dr} also holds for the doubly robust loss function.
	As a consequence we only need to model either $S(\cdot\vert X)$ or $G(\cdot\vert X)$ correctly in order to obtain a suitable estimator for $\mathcal{R}(\beta)$.
	
	As a next step we can plug in estimators $\hat{S}$ and $\hat{G}$ for the conditional survival functions $S_0$ and $G_0$ respectively to obtain empirical estimators for the full data loss.
	
	For the empirical Buckley--James loss we obtain
	\begin{equation*}
	L_{BJ}(\mathcal{O}, \beta; \hat{S}) = \frac{1}{n} \sum_{i=1}^n \left( \Delta_i L(h(T_i), \beta(X_i))+(1-\Delta_i)m_L(C_i, X_i, \beta; \hat{S})\right).
	\end{equation*}
	
	The empirical doubly robust loss function is given by
	\begin{equation*}
	\begin{split}
	L_{DR}(\mathcal{O}, \beta; \tilde{G}, \tilde{S}) ={} & \frac{1}{n} \sum_{i=1}^n \frac{\Delta_i L(h(T_i),\beta(X_i))}{\tilde{G}(\tilde{T}_i\vert X_i)}\\
	~ & + \frac{1}{n} \sum_{i=1}^n \left(\frac{(1-\Delta_i)m_L(\tilde{T_i}, X_i, \beta; \tilde{S})}{\tilde{G}(\tilde{T_i}\vert X_i)} \right.\\
	& - \left. \int _0^{\tilde{T_i}} \frac{m_L(u, X_i, \beta; \tilde{S})}{\tilde{G}(u \vert X_i)} d \Lambda_{\tilde{G}}(u \vert X_i) \right).
	\end{split}
	\end{equation*}
	
	If we use the incorrect model specification that $\hat{G}(t\vert X)=1$ for all~$t$, the empirical  Buckley--James loss is equivalent to the empirical doubly robust loss, i.e. $L_{BJ}(\mathcal{O}, \beta; \hat{S})=L_{DR}(\mathcal{O}, \beta; \hat{S}, \hat{G} = 1)$.
		
	We can now replace the full data loss function $L(h(T), f(X))$ in Algorithm \ref{alg:nocensor} with either the empirical Buckley--James loss $L_{BJ}$ or the empirical doubly robust loss $L_{DR}$ and obtain a prediction model that can be computed with the observed data~$\mathcal{O}$.
	We refer to the resulting algorithms as the Buckley--James or the doubly robust deep learning algorithms respectively.
	As both loss functions are censoring unbiased loss functions, we refer to the resulting algorithms as censoring unbiased deep learning (CUDL). 
	
	\subsection{Estimating Survival Probabilities $P(T\geq t \vert X)$}
	
	This section is based on \citet*{basearticle}.
	
	In this section we specify how the survival probabilities $P(T\geq t \vert X)$ can be estimated for a specified time point $t$.
	As mentioned before, the target parameter determines the choice of loss function.
	For the estimation of survival probabilities we can use the Brier loss $L_{t,2}(T, \beta(X)) = (I(T \geq t) - \beta(X))^2$ as our full data loss.
	
	As a first step we have to define a modified dataset with respect to the fixed time point $t$:
	\begin{equation*}
		\mathcal{O}(t) = \{(\tilde{T}_i(t)=\min(T_i, C_i, t), \Delta_i(t) = I(\min(T_i, t) \leq C_i), X_i); i = 1,\dots,n\}.
	\end{equation*}
	
	Using the Brier loss as the full data loss in Equation (\ref{eq:dr}) results in the doubly robust Brier loss, which is given by
	\begin{equation*}
	\begin{split}
		L_{DR, t}(\mathcal{O}(t),\beta; \hat{G},\hat{S}) &={}  \frac{1}{n} \sum_{i=1}^n \frac{\Delta_i(t)(I(\tilde{T}_i \geq t)-\beta(X_i))^2}{\hat{G}(\tilde{T}_i \vert X_i)}\\
		& + \frac{1}{n} \sum_{i=1}^n \frac{(1-\Delta_i(t))m_{L_2,t}(\tilde{T}_i(t),X_i,\beta; \hat{S})}{\hat{G}(\tilde{T}_i(t) \vert X_i)}\\
		& - \int_{0}^{\tilde{T}_i(t)} \frac{m_{L_2,t}(u,X_i,\beta; \hat{S})d\hat{\Lambda}_G(u\vert X_i)}{\hat{G}(u \vert X_i)},
	\end{split}
	\end{equation*}
	 with
	 \begin{equation*}
	 	m_{L_2,t}(u,X,\beta;S) = E_S[(I(\tilde{T}\geq t)-\beta(X))^2 \vert T \geq u, X].
	 \end{equation*}
	
	Analogously, by plugging in the Brier risk to the Buckley--James estimators we obtain the empirical Buckley--James Brier loss given by
	\begin{equation*}
		L_{BJ,t}(\mathcal{O},\beta; \hat{S}) = \frac{1}{n} \sum_{i=1}^n \left( \Delta_i(t)(I(\tilde{T}_i\geq t)-\beta(X_i))^2 + (1- \Delta_i(t))m_{L_2,t}(\tilde{T}_i(t), X_i; \hat{S})\right)
	\end{equation*}
	
	Both loss functions can now be incorporated in the CUDL algorithm and result in a prediction model for $P(T\geq t\vert X)$.

	\subsection{Estimating Mean Survival}
	
	This section relies on \citet*{basearticle} and \citet*{strawderman}.
	
	Another popular goal is to estimate the mean survival $E[T\vert X]$.
	For this target parameter we can use the $L_2$ loss as our full data loss and set $h(t)=t$.

	A direct estimation of the mean survival $E[T\vert X]$ requires strong assumptions.
	This is why we alternatively estimate the restricted mean survival $E[\min(T, \tau)\vert X]$ for a fixed constant $\tau$.
	
	Analogously to the estimation of survival probabilities, we need to incorporate the constant $\tau$ in the data set.
	This leads us to the modified version	
	\begin{equation*}
		\mathcal{O}(\tau) = \{(\tilde{T}_i(\tau) = \min\{T_i, C_i, \tau\}, \Delta_i(\tau) = I(\min\{T_i, \tau\}\leq C_i), X_i); i = 1, \dots , n\}.
	\end{equation*}
	
	Selecting the $L_2$ loss as the full data loss, choosing $h(t) = \min{t,\tau}$ and applying the CUDL algorithms to the modified data set gives us an estimator for the restricted mean survival.
	
	For a more detailed analysis of the estimation of restricted mean survival refer to \citet*{strawderman}. 
	
	\subsection{Implementation Based on a Doubly Robust Transformation}\label{trafo}

	This section follows the ideas presented in \citet*{basearticle}.
	
	We now describe how we can implement the doubly robust and Buckley--James CUDL algorithm using a specific response transformation.
	
		
	We use the following response transformation for each subject $i$ with observations $\mathcal{O}_i = (h(\tilde{T_i}), \Delta_i, X_i) \in \mathcal{O}$:
	\begin{equation*}
	D(\mathcal O_i; G,S) = A_{1i}+B_{1i} - C_{1i},
	\end{equation*}
	where for $k=0,1,2$
	\begin{equation*}
	A_{ki} = \frac{\Delta_i h(\tilde{T}_i)^k}{G(\tilde{T}_i\vert X_i)},
	\end{equation*}
	\begin{equation*}
	B_{ki} = \frac{(1-\Delta_i)m_k(\tilde{T}_i, X_i; S)}{G(\tilde{T}_i\vert X_i)}
	\end{equation*}
	and
	\begin{equation*}
	C_{ki} = \int_{0}^{\tilde{T}_i} \frac{m_k(u, X_i; S)}{G(u \vert X_i)}d\Lambda_G(u \vert X_i).
	\end{equation*}
	For $k=1,2$
	\begin{equation}\label{eq:condexp}
	m_k(t,X;S) = E_S[h^k(T) \vert T \geq t, X = x] = -[S(t\vert x)]^{-1} \int_{t}^{\infty}[h(u)^k]dS(u\vert x)
	\end{equation}
	and $m_0(t,X;S) = 1$ for all $t$.
	
	The transformation described above is equal to the doubly robust CUT described in Section \ref{sec:drtrafo} and thus requires that at least one of the models $T\vert X$ or $C \vert X$ is correctly specified.
	
	We can now define the response transformed $L_2$ loss, that uses the censoring unbiased outcome transformation $D(O_i;G,S)$ as the outcome:
	\begin{equation*}
	L_2^*(\mathcal{O}, \beta; G,S) = \frac{1}{n} \sum_{i=1}^n (D(O_i;G,S)-\beta(X_i))^2.
	\end{equation*}
	
	Our main goal is to show that a deep learning algorithm, that uses the transformed data and the response transformed $L_2$ loss, is equivalent to the CUDL algorithms presented in Section \ref{sec:cudls}.
	As a result, the deep learning algorithm that uses the transformed data inherits the desired doubly robustness property from the CUDL algorithm.
	
	This equivalence is stated in Theorem 1 in \citet*{basearticle} and reproduced below.
	
	\begin{Theorem}\label{thm:equi}
		Under mild regularity conditions, the prediction model created using the CUDL algorithm with the loss function $L_{DR}^{(2)}(\mathcal{O}, \beta; G,S)$ is identical to the prediction model built using the full data deep learning algorithm implemented using the loss function $L_2^*(\mathcal{O}, \beta; G,S)$.
	\end{Theorem}
	
	\begin{proof}
		Using the notation we introduced earlier in this section, we can rewrite the doubly robust loss function with the $L_2$ loss as the full data loss as:
		\begin{equation}\label{eq:rwdr}
		\begin{split}
		L_{DR}^{(2)}(\mathcal{O}, \beta; G,S) ={} \frac{1}{n} \sum_{i=1}^n & \left((A_{2i}+B_{2i}-C_{2i}) - 2(A_{1i}+B_{1i}-C_{1i})\beta(X_i) \right.\\
		& \left.+ (A_{0i}+B_{0i}-C_{0i})\beta(X_i)^2\right).
		\end{split}
		\end{equation}
		This equality can be shown by reordering the terms in the sum above in alphabetical order.
		
		Lemma \ref{lem:equi} provided in the appendix states that $A_{0i}+B_{0i}-C_{0i} = 1$.
		This observation leads us to
		\begin{equation*}
		L_{DR}^{(2)}(\mathcal{O}, \beta; G,S) = \frac{1}{n} \sum_{i=1}^n  \left((A_{2i}+B_{2i}-C_{2i}) - 2(A_{1i}+B_{1i}-C_{1i})\beta(X_i) + \beta(X_i)^2\right).
		\end{equation*}
		
		We can also reformulate the response transformed $L_2$ loss by expanding the square and obtain
		\begin{equation}\label{eq:rtl2}
		L_2^*(\mathcal{O}, \beta; G,S) = \frac{1}{n} \sum_{i=1}^n \left((A_{1i}+B_{1i}-C_{1i})^2 - 2 (A_{1i}+B_{1i}-C_{1i}) \beta(X_i)+\beta(X_i)^2\right).
		\end{equation}
		
		We can see that the loss functions in Equation (\ref{eq:rwdr}) and Equation (\ref{eq:rtl2}) are actually very similar.
		Only the first term in the sum, which is independent of $\beta$, is different for each loss function.
	
		As a consequence for a fixed penalization parameter $\eta$, minimizing 
		\begin{equation*}
		L_2^*(\mathcal{O}, \beta; G,S) + \eta \Vert \beta \Vert_p^2
		\end{equation*}
		and 
		\begin{equation*}
		L_{DR}^{(2)}(\mathcal{O}, \beta; G,S) + \eta \Vert \beta \Vert_p^2
		\end{equation*}
		 results in the same learning parameter $\beta$.
		 
		 If we can show that the penalization parameter selected by minimizing the cross-validated loss with the loss $L_2^*(\mathcal{O}, \beta; G,S)$ is the same if we replace the $L_2^*$ loss by $L_{DR}^{(2)}(\mathcal{O}, \beta; G,S)$, both prediction models produce the identical output.
		
		To show this, we use the notation from Section \ref{basicsdl}.
		Recall that $a_{i,\ell}$ indicates whether observation $i$ is an element of the subset $K_\ell$.
		
		As $L_2^*(\mathcal{O}, \beta; G,S)$ and $L_{DR}^{(2)}(\mathcal{O}, \beta; G,S)$ are equal up to a term that does not depend on $\beta$, it holds that
		\begin{equation*}
		\sum_{\ell=1}^{D} \sum_{i=1}^{n} a_{i,\ell} L_2^*(\mathcal{O}, \beta; G,S) = \sum_{\ell=1}^{D} \sum_{i=1}^{n} a_{i,\ell} L_{DR}^{(2)}(\mathcal{O}, \beta; G,S) + const(\mathcal{O}; G,S).
		\end{equation*}
		This shows that
		\begin{equation*}
		\begin{split}
		 &\argmin_{m \in \{1,\dots, M\}}\sum_{\ell=1}^{D} \sum_{i=1}^{n} a_{i,\ell} L_2^*(\mathcal{O}, \beta; G,S)\\
		  ={} &\argmin_{m \in \{1,\dots, M\}}\sum_{\ell=1}^{D} \sum_{i=1}^{n} a_{i,\ell} L_{DR}^{(2)}(\mathcal{O}, \beta; G,S),
		 \end{split}
		\end{equation*}
		which completes the proof.
	\end{proof}

	The assumptions on the conditional censoring function $G(\cdot\vert X)$ are flexible enough to allow for $G(t\vert X)=1$ for all $t$.
	And as it holds that $L_{BJ}(\mathcal{O}, \beta; \hat{S})=L_{DR}(\mathcal{O}, \beta; \hat{S}, \hat{G} = 1)$, Theorem \ref{thm:equi} also applies to the CUDL using the Buckley--James loss.
	
	Theorem \ref{thm:equi} allows us to implement the CUDL algorithm using techniques for fully observed outcomes.
	This leads us to the following algorithm, as described in \citet*{basearticle}:
	\begin{Algorithm}\label{alg:censor}~
		\begin{enumerate}
			\item Use the observed data $\mathcal{O}$ to compute estimators for the survival curves $\hat{S}(\cdot\vert\cdot)$ and $\hat{G}(\cdot\vert\cdot)$
			\item Perform the response transformation $D(O_i; \hat{G},\hat{S}),$~$ i = 1,\dots,n$
			\item Perform an $L_2$ full data deep learning algorithm, e.g. Algorithm \ref{alg:nocensor}, on the dataset $\{(D(O_i; \hat{G},\hat{S}), X_i); i = 1,\dots,n\}$.
		\end{enumerate}
	\end{Algorithm}

	In the following section we analyze the performance of the algorithm presented above in a simulation study.
	\newpage

	\section{Simulation Study} \label{simulation}
	In this section we compare the performance of the CUDL algorithms to a Cox PH model, a penalized Cox PH model and a survival tree method using simulated survival data.
	
	For comparison we estimate the conditional survival probability $P(T>t\vert X)$ for a prespecified time point $t$.
	
	\subsection{Simulation Settings}\label{settings}

	The different simulation settings follow those presented in \citet*{culs}.
	
	\begin{setting}
		In our first setting we simulate the dataset such that the proportional hazards assumption is met.
		To achieve this we create 300 independent observations with 25 explanatory variables $X=(X_1,\dots,X_{25})$.
		This vector is multivariate normal with mean zero and a covariance matrix $\Sigma$ with elements $\sigma_{ij}=0.9^{\vert i-j\vert}$.
		The survival times are then simulated from an exponential distribution with mean $\mu = \exp\left(0.1\sum_{i=9}^{18}X_i\right)$.
		As a consequence, only the explanatory variables $X_9,\dots,X_{18}$ are relevant for the survival time.
		The censoring distribution is also simulated from an exponential distribution with mean 0.5 which results in approximately 35\% censored data.
	\end{setting}

	\begin{setting}		
		In our second setting the proportional hazards assumption is mildly violated.
		Again, we simulate 300 independent observations with 25 explanatory variables $X=(X_1,\dots, X_{25})$.
		This vector now consists of 25 iid uniform random variables on the interval $[0,1]$.
		The survival time follows an exponential distribution with mean $\mu = \sin(X_1\pi)+2\vert X_2-0.5\vert + X_3^3$.
		This implies that only the explanatory variables $X_1,X_2,X_3$ matter for the survival time, the remaining explanatory variables $X_4,\dots,X_{25}$ are irrelevant.
		The censoring times are uniformly distributed on the interval $[0,6]$.
		This results in approximately 23\% censoring.
	\end{setting}
		
	\begin{setting}
		In this setting, the proportional hazards assumption is strongly violated.
		Our dataset consists of 300 independent observations and the explanatory variables $X=(X_1,\dots,X_{25})$ are each multivariate normal with mean zero and covariance matrix $\Sigma$ with $\sigma_{ij}=0.75^{\vert i-j\vert}$.
		Now, the survival times are simulated using the gamma distribution with  mean $\mu = 0.5 + 0.3 \vert \sum_{i=11}^{15} X_i \vert$ and scale parameter $\beta = 2$, which results in the shape parameter $\alpha = 2/\mu$.
		Here we consider that only the explanatory variables $X_{11},\dots,X_{15}$ are relevant for the survival time.
		The censoring times are uniformly distributed on the interval $[0,15]$.
		This leads to approximately 30\% censoring.
	\end{setting}

	\begin{setting}
		In the last setting we consider the case where the censoring distribution depends on the explanatory variables.
		Again, we simulate 300 independent observations where the explanatory variables $X=(X_1,\dots,X_{25})$ are multivariate normal with mean zero and the covariance matrix $\Sigma$ with elements $\sigma_{ij}=0.75^{\vert i-j\vert}$.
		The survival distribution is now a log-normal distribution with mean $\mu = 0.1 \vert \sum_{i=1}^5 X_i \vert + 0.1 \vert \sum_{i=16}^{20}X_i$.
		As a consequence the explanatory variables $X_{6},\dots,X_{15}$ and $X_{21},\dots,X_{25}$ are irrelevant for the survival time.
		The censoring times are also simulated according to a log-normal distribution with mean $\tilde{\mu}=\mu+0.5$ and scale parameter $\lambda = 1$.
		In this setting approximately 36\% of our data are censored.
	\end{setting}
			
	\subsection{Implementation of the CUDL Algorithm}\label{impl}
	For the implementation we adapted the \texttt{R} code of \citet*{basearticle} which is publicly available in one of the authors GitHub repository \url{https://www.github.com/jonsteingrimsson/CensoringDL}.
		
	\subsubsection{Estimating the Survival Curves $S_0(\cdot\vert\cdot)$ and $G_0(\cdot\vert\cdot)$}\label{estsurv}
	This section follows the ideas presented in \citet*{drcut} and \citet*{drtrees}.
	
	If the censoring time $C$ is completely independent of both, the event time $T$ and the explanatory variables $X$, the conditional censoring function $\tilde{G}(\cdot\vert X)=\tilde{G}(\cdot)$ can be efficiently estimated with the Kaplan--Meier (KM) estimator.
	The KM estimator for the censoring function is given by
	\begin{equation*}
		\hat{G}(t) = \prod_{i:\text{~} \tilde T_{(i)} \leq t} \left(1-\frac{1}{\#\{j: \tilde T_{(j)} \geq\tilde T_{(i)} \}}\right)^{1-\Delta_i},
	\end{equation*}
	where $\tilde T_{(1)}<\dots<\tilde T_{(n)}$ are the increasingly ordered observed times.
	
	For example if we consider that censoring is caused by the end of the study, the independence assumption stated above is met and the conditional censoring time can be computed using the KM estimator.
	
	To minimize the required number of assumptions and to cover previously excluded cases, we chose to estimate the censoring survival curve $G_0(t \vert X)$ using the survival tree method.
	This tree-based method extends the PH regression to tree-structured relative risk functions.
	The estimate is implemented in \texttt{R} in the following way.
	First, we fit a survival tree using the function \texttt{rpart} with all tuning parameters set to their default values.
	The function is provided in the package \texttt{rpart} and explained in greater detail in \citet*{rpart}.
	The tree method classifies the observations according to the explanatory variables in different subgroups.
	Within each subgroup a KM estimator is computed for the related data and then the estimators are connected to an overall estimator for the observations. %XXXX
	Further details can be found in \citet*{relativerisktrees}.
	
	The survival curve $S_0(t\vert X)$ should not be estimated using the KM estimator, as we presume that the observed time $\tilde T$ depends on the explanatory variables $X$.
	Instead, the survival curve is estimated via a random survival forest procedure.
	In \texttt{R} this estimator can be implemented using the function \texttt{rfscr} from the package \texttt{randomForestSRC}. 
	%For a detailed explanation refer to \citet*{drtrees}.
	
	It is possible to choose different estimation techniques for $S_0(\cdot\vert X)$ and $G_0(\cdot\vert X)$ respectively.
	
	When choosing the estimators it is important to avoid using an estimator for one of the functions that relies on the estimator of the other.
	This is because it would negatively impact the doubly robustness property, if we specify one of the estimators incorrectly and thus affect the consistency of the other.
	Further details can be found in \citet*{drtrees}.
	
	\subsubsection{Estimating the Conditional Expectation $m_k$}
	
	This section is based on \citet*{drtrees}.
	
	For the estimation of the conditional expectation $m_k$ given in equation (\ref{eq:condexp}), we assume that the observed time is transformed with the function $h(T) = I(T>t)$.
	Using this and plugging in the estimator of the survival curve $\hat{S}(\cdot\vert X)$ results in
	\begin{equation*}
	\begin{split}
	\hat{m}_{k,t} (u, X_i; \hat{S}) &={} E_{\hat{S}}[h^k(T)\vert T \geq u, X=X_i]\\
	&={}-\frac{1}{\hat{S}(u\vert X_i)}\int_u^{\infty}I(r> t)^kd\hat{S}(r\vert X_i)\\
	&={}-\frac{1}{\hat{S}(u\vert X_i)}\int_u^{\infty}I(r> t)d\hat{S}(r\vert X_i),
	\end{split}
	\end{equation*}
	for $k=1,2$.
	Because $h(T)$ is an indicator function, the conditional expectation does no longer depend on $k$.
	In this thesis, when estimating the survival curve we always use discrete estimators which have jumps at the finite observed event times $0=T_{(0)}<T_{(1)}<\dots<T_{(n)}$.
	As a consequence the integral is in fact a finite sum, given by
	\begin{equation*}
	\hat{m}_t (u, X_i; \hat{S}) = -\frac{1}{\hat{S}(u\vert X_i)}\sum_{i=1}^n I(T_{(i)}>t)(T_{(i)}-T_{(i-1)}),
	\end{equation*}
	which can be implemented in \texttt{R}.
	
	\subsubsection{Selecting Truncation Time to Ensure Positivity}
	
	This section relies on \citet*{drtrees}.
	
	For the methods described in Section \ref{censored} it is necessary to ensure that an empirical version of the positivity assumption holds meaning that for some $\varepsilon>0$ it holds for the empirical censoring function that $\hat{G}(t\vert X) \geq \varepsilon$.
	When computing the IPCW and the doubly robust mapping, having a denominator too close to zero can result in unstable finite sample performance.
	This is even the case if the empirical positivity assumption holds.
	
	To ensure that the empirical positivity assumption holds and that the empirical censoring function is not too small a truncation time $\tau>0$ is introduced.
	The general idea of truncation is to cut off the data after the truncation time $\tau$ meaning that for each observed survival time we set $\tilde{T}_i(\tau)=\min(\tilde{T}_i, \tau)$.
	There are different methods of truncation depending on how the event indicator $\Delta_i$ is changed and how the truncation time is selected.
	One possible approach is to set $$\Delta_i(\tau) = \Delta_i I(\tilde{T_i} \leq \tau)$$  for $i=1,\dots,n$ and choose the truncation time as the $95\%$ quantile of the observed times.
	In this setting we interpret each observed time that has been cut off as censored and keep the event indicator for data that has not been changed.
	The choice of truncation time leads to $5\%$ truncated data.
	
	A different approach, argued by \citet*{drtrees} on the basis of superior empirical results, is to set $$\Delta_i(\tau) = \Delta_i I(\tilde{T}_i\leq \tau) + I(\tilde{T}_i > \tau)$$ for $i=1,\dots,n$ and choose the truncation time as the $90\%$ quantile.
	In this scenario we treat each subject whose observed survival time exceeds the truncation time as if they experienced the event at time $\tau$.
	
	For the implementation we choose the truncation method as proposed by \citet*{drtrees}.
	\subsubsection{Preparation of Survival Data}
	
	We now describe how the transformation of the responses $\tilde T$ described in Section \ref{trafo}, namely the Buckley--James and the doubly robust transformation, can be implemented in \texttt{R}.
	
	For the Buckley--James transformation we estimate the conditional expectation $\hat{m}$ using the random forest method with the Brier loss as full data loss.
	The survival function is then computed with a survival tree, as described in Section \ref{estsurv}.
	In this case, the transformed response is given by
	\begin{equation*}
	Y^*_{BJ}(\mathcal{O}(t)) = \Delta(t)I(\tilde T>t)+ (1-\Delta(t))\hat{m}(\tilde T, X; \hat{S}),
	\end{equation*}
	which equals the Buckley--James transformation given in equation (\ref{eq:bjtrafo}) with the observations $\mathcal{O}(t)$.
	
	For the doubly robust transformation given in equation (\ref{eq:drcut}) we have to compute $A_{1i}$, $B_{1i}$ and $C_{1i}$.
	Again, we can plug in $h(\tilde T)=I(\tilde T>t)$, the estimated conditional expectation $\hat{m}$ and the estimated censoring function $\hat{G}$ and obtain
	\begin{equation*}
		A_{1i}(t)=\frac{\Delta_i(t)I(\tilde{T}_i >t)}{\hat{G}(\tilde{T}_i\vert X_i)},
	\end{equation*}
	\begin{equation*}
		B_{1i}(t) = \frac{(1-\Delta_i(t))\hat{m}(h(\tilde{T}_i), X_i; \hat{S})}{\hat{G}(\tilde{T}_i \vert X_i)}
	\end{equation*}
	and
	\begin{equation*}
	C_{1i}(t) = \int_{0}^{\tilde T_i}\frac{\hat{m}(h(u), X_i; \hat{S})}{\hat{G}(u\vert X_i)}d\Lambda_{\hat{G}}(u \vert X_i).
	\end{equation*}
	The parameter $C_{1i}(t)$ can again be computed using a finite sum.
	
	For comparison we split each dataset in a training and a test set.
	Analogous to \citet*{basearticle} we randomly chose $20\%$ of the data as our test set.
	In order to preserve the ratio of censored and uncensored data we draw the $20\%$ for the test set from the censored and uncensored data separately.
	
	\subsubsection{Competing Methods}\label{comp}
	
	In this section we describe how the deep learning model from Algorithm \ref{alg:censor} can be implemented in \texttt{R}.
	Then we explain three different methods for estimation of survival time that we use to compare the performance of the CUDL algorithms.
	
	To predict the survival probabilities with deep learning we use a feedforward network with two layers.
	The first layer consists of 15 units and uses the ReLU activation function $\phi(x) = \max(0, x)$.
	As proposed in \citet*{deeplbook} we use the dropout rate $1-p=0.2$ for the input layer.
	The second layer, which is our output layer, consists of one unit and uses the sigmoid activation function $\phi(x)=(1+e^{-x})^{-1}$.
	We choose this activation function to make sure that the resulting value can be interpreted as a probability.
	
	For the gradient descent we use the mean squared error as loss function, the batch size is set to 32 and we use 100 epochs.
	In one epoch we go through the whole dataset in batches of 32, which means that we perform the gradient descent algorithm $(\# \text{observations})/32\cdot100$ -- times to find the optimal parameter.
	Then we perform 5-fold cross validation to choose a suitable penalization term $\eta$ from the sequence $(0, 0.001, 0.01, 0.1)$.
	As proposed by \citet*{basearticle} the performance of the resulting penalized feedforward network is evaluated with an IPCW weighted mean squared error.
	This error is computed estimating the IPCW weights which are described in Equation (\ref{eq:ipcw}) and multiplying them with the mean squared error.
	
	The procedure described above is performed twice.
	For the observed times that are transformed using the Buckley--James transformation and for the doubly robust transformed observed times.
	
	We compare the deep learning algorithms that use the transformed data to three different approaches: a Cox PH model, a penalized Cox model and a random forest model.
	As a first step, we transform the responses $Y=h(T)=I(T>t)$, with the prespecified time point $t$ to account for the goal of estimating survival probabilities.
	
	The Cox PH model, which is explained in further detail in Section \ref{cox}, can be estimated in \texttt{R} using the function \texttt{coxph} from the package \texttt{survival}.
	Refer to \citet*{survival-package} for further information.
	We then create the corresponding survival curve using the function \texttt{survfit}.
	
	The second model, which is the penalized Cox model, is very similar to the Cox PH model.
	As a first step, a cross validated generalized linear model is evaluated to determine the explanatory variables that need to be included in the model to minimize the mean cross-validated error.
	These explanatory variables are then used to fit a Cox PH model in the same way as described earlier in this section.
	
	As a third model we consider a random forest model.
	This can be implemented using the \texttt{R} function \texttt{rfscr} from the package \texttt{randomForestSRC}.
	The resulting survival curve is estimated using the function \texttt{predict}.
	
	The performance of all of the above mentioned models is again evaluated using an IPCW weighted mean squared error.
	
	\subsection{Simulation Results}
	In this section we compare the different methods for survival analysis, which are described in Section \ref{comp}  for each of the settings presented in Section~\ref{settings}.
	
	First the data is generated according to the current setting.
	For the CUDL algorithms the observed time is using the Buckley--James and the doubly robust transformation respectively.
	Then the 300 observations are randomly split in a training and test set where the test set contains $20\%$ of the data.
	The different methods are fit using the training data and evaluated with the IPCW weighted error.
	We repeat this procedure 50 times and compare the resulting errors.
	
	For predicting the survival probability $P(T>t\vert X)$ we have to specify the time $t$.
	Analogous to \citet*{basearticle} we used the median survival time for each setting.
	We empirically computed the median by simulating the data 1000 times and taking the mean.%XXX
	
	The resulting prediction errors are visualized using raincloud plots.
	These plots extend boxplots by the empirical distribution of the considered data.
	%XXX
	
	In Setting 1 we compute the survival times such that the PH assumption is met.
	We used the empirically computed median $t = 0.4189946$ for the estimation.
	Each of the considered models gives comparably good results.
	In the 
	\begin{figure}\label{setting1}
		\centering	
		\input{../plots/setting1.tex}
		\vspace{-0.3cm}
		\caption{Comparison of the resulting IPCW weighted mean squared error for Setting 1. Lower values indicate better performance. BJCUDL and drCUDL are the CUDL algorithms that use the Buckley--James and the doubly robust transformation respectively. The Cox PH model and the penalized Cox PH model are denoted by cox and pencox. Rand is the random forest procedure.}
 	\end{figure}
	
	In Setting 2 we compute the survival times such that the PH assumption is mildly violated.
	We used the empirically computed median $t = 0.7046207$ for the estimation.
	
	Penalized Cox and random forest are both significantly better than deep learning approaches.
	Doubly robust performs better than Buckley--James.
	
	\begin{figure}\label{setting2}
		\centering	
		\input{../plots/setting2.tex}
		\vspace{-0.3cm}
		\caption{Comparison of the resulting IPCW weighted mean squared error for Setting 2. Lower values indicate better performance. The names of the different models are chosen as in Figure~\ref{setting1}.}
	\end{figure}
	
	In Setting 3 we compute the survival times such that the PH assumption is strongly violated.
	We used the empirically computed median $t = 2,90718$ for the estimation.
	
	\begin{figure}\label{setting3}
		\centering	
		\input{../plots/setting3.tex}
		\vspace{-0.3cm}
		\caption{Comparison of the resulting IPCW weighted mean squared error for Setting 3. Lower values indicate better performance. The names of the different models are chosen as in Figure~\ref{setting1}.}
	\end{figure}
	
	In Setting 4 we compute the survival times such that the censoring distribution depends on the explanatory variables.
	We used the empirically computed median $t = 1,034881$ for the estimation.
	
	\begin{figure}\label{setting4}
		\centering	
		\input{../plots/setting4.tex}
		\vspace{-0.3cm}
		\caption{Comparison of the resulting IPCW weighted mean squared error for Setting 4. Lower values indicate better performance. The names of the different models are chosen as in Figure~\ref{setting1}.}
	\end{figure}
	
	\begin{table}
		\footnotesize
		{\tabcolsep=0pt\def\arraystretch{1.3}
			\begin{tabularx}{\textwidth}{l *{4}{>{\Centering}X}}
				\toprule
				algorithm & 10\% quantile & mean & 90\% quantile & standard deviation\tabularnewline
				\multicolumn{5}{c}{Setting 1}\tabularnewline
				\cmidrule(lr){2-5}
				BJCUDL	& 0.1905			& 0.2322			& \textbf{0.2714}	& \textbf{0.0372} \tabularnewline
				cox 	& 0.1964			& 0.2485			& 0.3098			& 0.0458 \tabularnewline
				drCUDL	& 0.1858			& 0.2444			& 0.2960			& 0.0414 \tabularnewline
				pencox 	& 0.1858			& 0.2319			& 0.2862			& 0.0436 \tabularnewline
				rand 	& \textbf{0.1852}	& \textbf{0.2301}	& 0.2773			& 0.0401 \tabularnewline
				
				\multicolumn{5}{c}{Setting 2}\tabularnewline
				\cmidrule(lr){2-5}
				BJCUDL 	& 0.2592			& 0.2771			& 0.2997			& \textbf{0.0163} \tabularnewline
				cox 	& 0.2590			& 0.2939			& 0.3327			& 0.0292 \tabularnewline
				drCUDL 	& \textbf{0.2434}	& 0.2828			& 0.3170			& 0.0349 \tabularnewline
				pencox 	& 0.2581			& 0.2795			& 0.3115			& 0.0224 \tabularnewline
				rand 	& 0.2527			& \textbf{0.2719}	& \textbf{0.2955}	& 0.0183 \tabularnewline
				
				\multicolumn{5}{c}{Setting 3}\tabularnewline
				\cmidrule(lr){2-5}
				BJCUDL 	& 0.1000			& \textbf{0.2375}	& \textbf{0.3074}	& \textbf{0.0810} \tabularnewline
				cox 	& \textbf{0.0912}	& 0.2507			& 0.3350			& 0.0925 \tabularnewline
				drCUDL 	& 0.0970			& 0.2441			& 0.3166			& 0.0868 \tabularnewline
				pencox 	& 0.0943			& 0.2377			& 0.3092			& 0.0867 \tabularnewline
				rand 	& 0.0956			& 0.2399			& 0.3084			& 0.0850 \tabularnewline
				
				\multicolumn{5}{c}{Setting 4}\tabularnewline
				\cmidrule(lr){2-5}
				BJCUDL 	& 0.2122			& 0.2683			& 0.3238			& \textbf{0.0422} \tabularnewline
				cox 	& 0.2210			& 0.2844			& 0.3479			& 0.0610 \tabularnewline
				drCUDL 	& 0.2099			& 0.2705			& 0.3278			& 0.0498 \tabularnewline
				pencox 	& \textbf{0.2053}	& \textbf{0.2650}	& \textbf{0.3221}	& 0.0435 \tabularnewline
				rand 	& 0.2058			& 0.2716			& 0.3265			& 0.0463 \tabularnewline
				\bottomrule
				
		\end{tabularx}}
		\caption{Comparison of 10\%- and 90\% quantile, mean and standard deviation of the prediction error of the models for each of the settings described above. The names of the different models are chosen as in Figure~\ref{setting1}.}
	\end{table}
	

	\newpage
	\section{Application to a Real World Scenario}
	In this section we analyze the performance of the models described in Section \ref{impl} when applied to a real world scenario.
	
	\subsection{Mayo Clinic Primary Biliary Cholangitis Data}
	The Mayo Clinic primary biliary cholangitis data can be found in the \texttt{R} package \texttt{survival} and is provided by \citet*{survival-book}.
	
	Primary biliary cholangitis (PBC) is an autoimmune disease that leads to demolition of the small bile ducts in the liver.
	The disease progresses slow but is inexhortable and can lead to cirrhosis and liver decompensation.
	The data originates from the Mayo Clinic trial in PBC that was carried out between 1974 and 1984.
	In this ten year interval a total of 312 PBC patients took part in the randomized placebo controlled trial of the drug D-penicillamine.
	Additional 106 cases did not participate in the clinical trial but were followed for survival.
	This results in data of 418 individuals.
	
	For further computations we exclude cases with missing explanatory variables.
	This leads to 276 observations that can be used for our models.
	
	In the data set the survival time of each individual is given by the variable \texttt{time}.
	It describes the number of days between registration and either death, transplantation or the end of the study and takes values between 41 and 4795.
	The \texttt{status} variable is an event indicator for three possible cases, either the patient was right censored, received a transplant or experienced the event meaning that the subject died.
	As we only consider one event instead of two, each patient that received a transplant is treated as censored.
	This leads to approximately $59.78\%$ censoring.
	
	The data set contains 17 explanatory variables, which are age in years, sex, a treatment variable that indicates if the patient was in the placebo or treatment group or was not part of the clinical trial and various other medical features that might influence the survival time.
	All of the given explanatory variables are transformed into numerical values.
	
	As a next step we added uniformly distributed noise in the range $[0, 0.1]$ to assure that each observed survival time is different.
	This is important for the estimation of the survival and censoring functions, as estimators like the KM estimator assume the observed times to be distinct.
	
	We estimate the survival probabilities using 50 equidistant time points on the interval $[850,4500]$.
	The lower bound of this interval was chosen to ensure that at least five subjects in the dataset were censored beforehand.
	This prevents the estimation procedures described in Section \ref{impl} from using a constant estimator for the censoring function.
	
	For each time point we randomly split the data into a training and test set and compute the prediction error of the five models described in Section \ref{impl} to compare their performance. 
	As proposed by \citet*{basearticle} we use $20\%$ of the data as the test set. 
	\subsection{Results}
	%\todo[inline]{maybe change title}
	
	\todo[inline]{evaluate algorithms with data set}
	
	\begin{figure}\label{plot:realdata}
		\centering	
		\input{../plots/realData.tex}
		\vspace{-0.3cm}
		\caption{Comparison of the resulting IPCW weighted mean squared error for the PBC data. Lower values indicate better performance. BJCUDL and drCUDL are the CUDL algorithms that use the Buckley--James and the doubly robust transformation respectively. The Cox PH model and the penalized Cox PH model are denoted by cox and pencox. Rand is the random forest procedure.}
	\end{figure}

	\begin{table}
		\footnotesize
		{\tabcolsep=0pt\def\arraystretch{1.3}
			\begin{tabularx}{\textwidth}{l *{4}{>{\Centering}X}}
				\toprule
				algorithm & 10\% quantile & mean & 90\% quantile & standard deviation\tabularnewline
				\toprule
				BJCUDL 	& 0.1263			& 0.3257			& 0.5554			& 0.1584 \tabularnewline
				cox 	& 0.0756			& 0.1572			& 0.3011			& 0.0872 \tabularnewline
				drCUDL 	& 0.1812			& 0.3707			& 0.5504			& 0.1549 \tabularnewline
				pencox 	& \textbf{0.0679}	& 0.1544			& 0.3022			& 0.0891 \tabularnewline
				rand 	& 0.0730			& \textbf{0.1532}	& \textbf{0.2491}	& \textbf{0.0761} \tabularnewline
				\bottomrule
				
		\end{tabularx}}
		\caption{Comparison of 10\%- and 90\% quantile, mean and standard deviation of the prediction error of the models for the Mayo clinic primary biliary cholangitis data. The names of the models are chosen as in Figure \ref{plot:realdata}.}
	\end{table}
	

	\todo[inline]{compare resulting error}
	\newpage
	
	\section{Conclusion}
	In this thesis we briefly described the main concepts of survival analysis and deep learning respectively.
	Then we analyzed how feedforward networks can be applied to uncensored data.
	In the main part we considered censored data and studied how existing algorithms can be extended to survival data.
	To achieve this we first introduced the concept of censoring unbiased transformations which preserve the conditional mean structure of the data. %add Buckley--James and doubly robust transformation
	These transformations were then applied to full data loss functions which resulted in the class of censoring unbiased deep learning algorithms.
	Then we proved that these algorithms are equivalent to deep learning algorithms that use the full data loss with transformed data as input.
	As a next step we evaluated the performance of these deep learning algorithms in four different settings.
	%add results
	To conclude this thesis we also applied the methods to the Mayo clinic primary biliary cholangitis data.
	
	
	
	evtl als Ausblick: Erweiterung auf competing risks, time dependent explanatory variables, recurrent events; Test different estimators for $S$ and $G$
	
	\newpage
	
	\thispagestyle{empty}
	\bibliographystyle{chicago}
	\bibliography{mareference}
	
	\newpage
	
	\begin{appendices}
		\section{Regularity Conditions}\label{regcond}
		As proposed in Theorem 3.1 in \citet*{drcut} we make the following assumptions.
		Suppose that the observed time $\tilde T$ and the censoring time $C$ are continuous random variables, that they are conditionally independent given the explanatory variables $X$, and that the conditional distribution $F_0(\cdot \vert X) = 1 - G_0(\cdot \vert X)$ has a conditional density $f_0(\cdot \vert X)$.
		Assume that $\tilde T \leq \tau < \infty$ for some $\tau$ and that $\tilde{S}(\tau \vert X)=0$ with probability one for some conditional function $\tilde{S}(\cdot \vert X)$.
		Suppose further that $\tilde{G}(\tau \vert X)\geq \varepsilon > 0$ for some~$\varepsilon$ and conditional survival function $\tilde{G}(\cdot \vert X)$, with corresponding conditional density $\tilde{g}(\cdot\vert X)$.
		Assume that $\tilde{g}(\cdot\vert X)$ is absolutely continuous with respect to $g_0(\cdot\vert X)$ for all~$X$.
		We will use the convention that $m(t,X;\tilde{S})$ is set to zero if $\tilde{S}(t \vert X)=0$.
		\section{Proofs}
		\subsection{Proof of Theorem \ref{thm:bj}}\label{proof:bjcut}
		\textbf{Theorem {5.1.}} \textit{Under the mild regularity conditions given in Appendix~\ref{regcond} it holds that $Y_{BJ}^*(\cdot; S_0)$ is a CUT.}
		\begin{proof}
			The transformation $Y_{BJ}^*(\mathcal{O}; S_0)$ is a CUT if $E[Y_{BJ}^*(\mathcal{O}; S_0)\vert X] = E[Y\vert X]$ holds.
			
			Because of the linearity of expectation we can analyze each term in $Y_{BJ}^*(\mathcal{O}; S_0)$ separately.
			For the first term we obtain:
			\begin{equation*}
			\begin{split}
			E[\Delta Y\vert X] &={} E[E[\Delta Y \vert Y, X]\vert X] = E[Y P(\Delta = 1\vert Y,X)\vert X]\\
			&={} E[Y G(Y\vert X)\vert X] = \int_{0}^{\tau} y G(y\vert X)d(1-S(y\vert X))\\
			&={} - \int_{0}^{\tau} y G(y\vert X)dS(y\vert X)
			\end{split}
			\end{equation*}
			For the second term we obtain:
			\begin{equation*}
			\begin{split}
			E[(1-\Delta)m(Y,X;S)] &={} E[E[(1-\Delta)m(Y,X;S)\vert Y,X]\vert X]\\
			&={} E[m(Y,X;S)P(\Delta = 0\vert Y, X)\vert X]\\
			&={} E[m(Y,X;S)S(Y\vert X)\vert X]\\
			&={} E\left[-\frac{S(Y\vert X)}{S_0(Y\vert X)}\int_{Y}^{\tau}ydS_0(y\vert X)\right]\\
			&={} \int_{0}^{\tau}\frac{S(c\vert X)}{S_0(c\vert X)}\int_{Y}^{\tau}ydS_0(y\vert X)dG(c\vert X)\\
			&={} \int_0^{\infty}\int_0^{\infty} \frac{S(c\vert X)}{S_0(c\vert X)} I(c <y<\tau) y dS_0(y\vert X)dG(c\vert X)\\
			&={} \int_0^{\tau}y\int_0^y \frac{S(c\vert X)}{S_0(c\vert X)} dG(c\vert X)dS_0(y\vert X)
			\end{split}
			\end{equation*}
			Combining both and setting $S=S_0$ yields
			\begin{equation*}
			\begin{split}
			E[Y_{BJ}^*(\mathcal{O}; S_0)\vert X] &= E[\Delta Y\vert X] + E[(1-\Delta)m(Y,X;S_0)]\\
			&={} - \int_{0}^{\tau} y G(y\vert X)dS_0(y\vert X) + \int_0^{\tau}y\int_0^y \frac{S_0(c\vert X)}{S_0(c\vert X)} dG(c\vert X)dS_0(y\vert X)\\
			&={} - \int_{0}^{\tau} y \left[G(y\vert X)-\int_0^ydG(c\vert X)\right]dS_0(y\vert X)\\
			&={} - \int_{0}^{\tau} y \left[G(y\vert X)-(G(y\vert X)-1)\right]dS_0(y\vert X)\\
			&={} - \int_{0}^{\tau} ydS_0(y\vert X)\\
			&={} E[Y\vert X]. \qedhere
			\end{split}
			\end{equation*}
		\end{proof}
		\subsection{Auxiliary Lemma for Theorem \ref{thm:equi}}\label{proof:strawderman}
		
		\begin{Lemma}\label{lem:equi}
			Using the notation introduced in Section \ref{trafo}, it holds that 
			\begin{equation*}
				A_{0i}+B_{0i}-C_{0i}=1
			\end{equation*}
		\end{Lemma}
		\begin{proof}
			By plugging in the definitions of $A_{0i}$, $B_{0i}$ and $C_{0i}$ respectively, we obtain
			\begin{equation*}
			A_{0i}+B_{0i}-C_{0i} = \frac{\Delta_i}{G(T_i\vert X_i)} + \frac{1-\Delta_i}{G(T_i\vert X_i)} - \int_{0}^{T_i}\frac{1}{G(u\vert X_i)}d\Lambda_G(u\vert X_i)
			\end{equation*}
			We can now combine the first two terms to obtain
			\begin{equation}\label{eq:lemma}
			A_{0i}+B_{0i}-C_{0i} = \frac{1}{G(T_i \vert X_i)} - \int_{0}^{T_i}\frac{1}{G(u\vert X_i)}d\Lambda_G(u\vert X_i).
			\end{equation}
			This formulation allows us to apply Lemma 1 from \citet*{strawderman}.
			Using the notation introduced in this thesis, the aforementioned lemma gives us the following equation:
			\begin{equation}\label{eq:straw}
			\frac{\Delta^*_i}{G(T_i\vert X_i)} = 1 - \int_{0}^{\infty} \frac{1}{G(s\vert X_i)} dM^*(s),
			\end{equation}
			with
			\begin{equation*}
			M^*(s) = I\{T_i \leq s, \Delta^*_i=0\} - \int_{0}^s I\{T_i\geq u\}d\Lambda_G(u\vert X_i),
			\end{equation*}
			and $\Delta^*$ is any arbitrary indicator function.
			
			Now we set $ \Delta^*_i=1$ for all $i=1,\dots,n$ and take a closer look at the definition of the function $M^*(s)$.
			\begin{equation*}
			\begin{split}
			M^*(s) &={} I\{T_i \leq s, \Delta^*_i = 0\} - \int_{0}^s I\{T_i\geq u\}d\Lambda_G(u\vert X_i)\\
			& ={} - \int_{0}^s I\{T_i\geq u\}d\Lambda_G(u\vert X_i)\\
			& ={} - \int_0^{min\{T_i,s\}}d\Lambda_G(u\vert X_i)\\
			& ={} - \left(\Lambda_G(min\{T_i,s\}\vert X_i)-\Lambda_G(0\vert X_i)\right)\\
			& ={} - \Lambda_G(min\{T_i,s\}\vert X_i)
			\end{split}
			\end{equation*}
			Now we can plug in our choice of $\Delta^*_i$ and $M^*(s)$ to equation (\ref{eq:straw}).
			\begin{equation}\label{eq:straw_trafo}
			\begin{split}
			\frac{1}{G(T_i\vert X_i)} &={} 1 + \int_{0}^{\infty} \frac{1}{G(s\vert X_i)} d\Lambda_G(min\{T_i,s\}\vert X_i)\\
			&={} 1 + \int_{0}^{T_i} \frac{1}{G(s\vert X_i)} d\Lambda_G(s\vert X_i) + \int_{T_i}^{\infty} \frac{1}{G(s\vert X_i)} d\Lambda_G(T_i\vert X_i)\\
			& ={} 1 + \int_{0}^{T_i} \frac{1}{G(s\vert X_i)} d\Lambda_G(s\vert X_i)
			\end{split}
			\end{equation}
		
			Combining equation (\ref{eq:lemma}) and (\ref{eq:straw_trafo}) now yields:
			\begin{equation*}
			\begin{split}
			A_{0i}+B_{0i}-C_{0i}&={}\frac{1}{G(T_i \vert X_i)} - \int_{0}^{T_i}\frac{1}{G(u\vert X_i)}d\Lambda_G(u\vert X_i)\\
			&={} 1 + \int_{0}^{T_i} \frac{1}{G(s\vert X_i)} d\Lambda_G(s\vert X_i)  - \int_{0}^{T_i}\frac{1}{G(u\vert X_i)}d\Lambda_G(u\vert X_i)\\
			&={} 1. \qedhere
			\end{split}
			\end{equation*}
		\end{proof}
	
		%\section{Further Simulations}
		
		%\section{R-Code}
		
	\end{appendices}
	
\end{document}